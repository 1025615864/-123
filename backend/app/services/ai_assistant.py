"""AIæ³•å¾‹å’¨è¯¢åŠ©æ‰‹æœåŠ¡"""
import uuid
import logging
import time
from typing import Any, cast

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

from app.config import get_settings
from app.schemas.ai import LawReference

settings = get_settings()

logger = logging.getLogger(__name__)


class LegalKnowledgeBase:
    """æ³•å¾‹çŸ¥è¯†åº“ç®¡ç†"""
    
    def __init__(self):
        self.embeddings = None
        self.vector_store: Chroma | None = None
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", "ã€‚", "ï¼›", " "]
        )
        self._initialized = False
    
    def initialize(self):
        """åˆå§‹åŒ–æˆ–åŠ è½½å‘é‡æ•°æ®åº“"""
        if self._initialized:
            return
        
        try:
            if settings.openai_api_key:
                self.embeddings = OpenAIEmbeddings(
                    api_key=cast(Any, settings.openai_api_key),
                    base_url=settings.openai_base_url
                )
                self.vector_store = Chroma(
                    persist_directory=settings.chroma_persist_dir,
                    embedding_function=self.embeddings,
                    collection_name="legal_knowledge"
                )
            self._initialized = True
        except Exception:
            logger.exception("åˆå§‹åŒ–å‘é‡æ•°æ®åº“å¤±è´¥")
            self._initialized = True
    
    def add_law_documents(self, documents: list[dict[str, object]]):
        """æ·»åŠ æ³•å¾‹æ–‡æ¡£åˆ°çŸ¥è¯†åº“
        
        Args:
            documents: æ³•å¾‹æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å« law_name, article, content
        """
        if not self.vector_store:
            self.initialize()
        
        texts = []
        metadatas = []
        
        for doc in documents:
            content = f"ã€{str(doc.get('law_name', ''))}ã€‘{str(doc.get('article', ''))}\n{str(doc.get('content', ''))}"
            texts.append(content)
            metadatas.append({
                "law_name": str(doc.get('law_name', '')),
                "article": str(doc.get('article', '')),
                "source": str(doc.get('source', '')),
            })
        
        if texts and self.vector_store:
            self.vector_store.add_texts(texts=texts, metadatas=metadatas)
    
    def search(self, query: str, k: int = 5) -> list[tuple[str, dict[str, object], float]]:
        """æœç´¢ç›¸å…³æ³•å¾‹æ¡æ–‡
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            List of (content, metadata, score)
        """
        if not self.vector_store:
            self.initialize()

        if self.vector_store is None:
            return []
        
        try:
            results = self.vector_store.similarity_search_with_score(query, k=k)
            return [(doc.page_content, doc.metadata, score) for doc, score in results]
        except Exception:
            logger.exception("æœç´¢å¤±è´¥")
            return []


class AILegalAssistant:
    """AIæ³•å¾‹å’¨è¯¢åŠ©æ‰‹"""
    
    SYSTEM_PROMPT = """ä½ æ˜¯"ç™¾å§“æ³•å¾‹åŠ©æ‰‹"çš„AIæ³•å¾‹å’¨è¯¢å‘˜ï¼Œä¸“é—¨ä¸ºæ™®é€šç™¾å§“æä¾›æ³•å¾‹å’¨è¯¢æœåŠ¡ã€‚

## ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
1. åŸºäºä¸­å›½æ³•å¾‹æ³•è§„ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„æ³•å¾‹å’¨è¯¢
2. ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæ³•å¾‹æ¦‚å¿µ
3. **ç²¾å‡†å¼•ç”¨æ³•æ¡**ï¼šå›ç­”æ—¶å¿…é¡»å¼•ç”¨å…·ä½“çš„æ³•å¾‹æ¡æ–‡ä½œä¸ºä¾æ®
4. å¯¹äºå¤æ‚æ¡ˆä»¶ï¼Œå»ºè®®ç”¨æˆ·å¯»æ±‚ä¸“ä¸šå¾‹å¸ˆå¸®åŠ©

## å›ç­”æ ¼å¼è§„èŒƒï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š

### 1. é—®é¢˜ç†è§£
é¦–å…ˆç®€è¦æ¦‚æ‹¬ç”¨æˆ·çš„æ³•å¾‹é—®é¢˜å’Œæ ¸å¿ƒè¯‰æ±‚ã€‚

### 2. æ³•å¾‹åˆ†æ
ç»“åˆç›¸å…³æ³•å¾‹æ¡æ–‡è¿›è¡Œè¯¦ç»†åˆ†æï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼å¼•ç”¨æ³•æ¡ï¼š
> ğŸ“œ **ã€Šæ³•å¾‹åç§°ã€‹ç¬¬Xæ¡**ï¼šå…·ä½“æ¡æ–‡å†…å®¹

### 3. é£é™©è¯„ä¼°
æ ¹æ®ç”¨æˆ·æè¿°çš„æƒ…å†µï¼Œç»™å‡ºé£é™©ç­‰çº§è¯„ä¼°ï¼š
- ğŸŸ¢ **ä½é£é™©**ï¼šæ³•å¾‹å…³ç³»æ˜ç¡®ï¼Œèƒœè¯‰å¯èƒ½æ€§è¾ƒé«˜
- ğŸŸ¡ **ä¸­é£é™©**ï¼šå­˜åœ¨äº‰è®®ç‚¹ï¼Œéœ€è¦è¡¥å……è¯æ®
- ğŸ”´ **é«˜é£é™©**ï¼šæ³•å¾‹ä¾æ®ä¸è¶³æˆ–å¯¹æ–¹å ä¼˜åŠ¿

### 4. è¡ŒåŠ¨å»ºè®®
ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„å»ºè®®æ­¥éª¤ã€‚

### 5. è¿½é—®ç¡®è®¤ï¼ˆå¦‚éœ€è¦ï¼‰
å¦‚æœä¿¡æ¯ä¸è¶³ä»¥ç»™å‡ºå‡†ç¡®å»ºè®®ï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿½é—®ï¼š
â“ **ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨ï¼Œè¯·è¡¥å……ä»¥ä¸‹ä¿¡æ¯ï¼š**
1. [å…·ä½“é—®é¢˜1]
2. [å…·ä½“é—®é¢˜2]

## æ™ºèƒ½è¿½é—®åœºæ™¯ï¼š
å½“ç”¨æˆ·æè¿°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œä¸»åŠ¨è¿½é—®å…³é”®ä¿¡æ¯ï¼š
- åŠ³åŠ¨çº çº·ï¼šæ˜¯å¦ç­¾è®¢åŠ³åŠ¨åˆåŒï¼Ÿå·¥ä½œå¹´é™ï¼Ÿæ˜¯å¦æœ‰è¯æ®ï¼Ÿ
- å©šå§»å®¶åº­ï¼šå©šå§»çŠ¶å†µï¼Ÿè´¢äº§æƒ…å†µï¼Ÿå­å¥³æŠšå…»æ„æ„¿ï¼Ÿ
- åˆåŒçº çº·ï¼šåˆåŒæ˜¯å¦ä¹¦é¢ï¼Ÿè¿çº¦æ¡æ¬¾ï¼ŸæŸå¤±é‡‘é¢ï¼Ÿ
- äº¤é€šäº‹æ•…ï¼šè´£ä»»è®¤å®šä¹¦ï¼Ÿä¿é™©æƒ…å†µï¼Ÿä¼¤äº¡ç¨‹åº¦ï¼Ÿ
- å€Ÿè´·çº çº·ï¼šæ˜¯å¦æœ‰å€Ÿæ¡ï¼Ÿé‡‘é¢ï¼Ÿè¿˜æ¬¾æœŸé™ï¼Ÿ

## æ³¨æ„äº‹é¡¹ï¼š
- å¦‚æœé—®é¢˜ä¸åœ¨ä½ çš„çŸ¥è¯†èŒƒå›´å†…ï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·
- å¯¹äºæ¶‰åŠäººèº«å®‰å…¨çš„ç´§æ€¥æƒ…å†µï¼Œæé†’ç”¨æˆ·åŠæ—¶æŠ¥è­¦ï¼ˆ110ï¼‰
- ä¸è¦æä¾›ä»»ä½•è¿æ³•å»ºè®®
- å¯¹äºåˆ‘äº‹æ¡ˆä»¶ï¼Œå¼ºçƒˆå»ºè®®è˜è¯·ä¸“ä¸šå¾‹å¸ˆ
- æ¶‰åŠé‡‘é¢è¶…è¿‡10ä¸‡å…ƒçš„æ¡ˆä»¶ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ

## ç›¸å…³æ³•å¾‹å‚è€ƒï¼š
{context}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å’Œæ ¼å¼è§„èŒƒå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""

    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.ai_model,
            api_key=cast(Any, settings.openai_api_key),
            base_url=settings.openai_base_url,
            temperature=0.7,
            max_completion_tokens=2000
        )
        self.knowledge_base = LegalKnowledgeBase()
        self.knowledge_base.initialize()
        self.conversation_histories: dict[str, list[dict[str, str]]] = {}
        self._last_seen: dict[str, float] = {}
        self._max_sessions = 5000
        self._max_messages_per_session = 50

    def _evict_if_needed(self) -> None:
        if len(self.conversation_histories) <= self._max_sessions:
            return

        oldest_session: str | None = None
        oldest_time = float("inf")
        for sid, ts in self._last_seen.items():
            if ts < oldest_time:
                oldest_time = ts
                oldest_session = sid

        if oldest_session is not None:
            self.conversation_histories.pop(oldest_session, None)
            self._last_seen.pop(oldest_session, None)
    
    def _build_context(self, references: list[tuple[str, dict[str, object], float]]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
        if not references:
            return "æš‚æ— ç›¸å…³æ³•å¾‹æ¡æ–‡å‚è€ƒï¼Œè¯·åŸºäºä½ çš„æ³•å¾‹çŸ¥è¯†å›ç­”ã€‚"
        
        context_parts = []
        for i, (content, metadata, score) in enumerate(references, 1):
            context_parts.append(f"{i}. {content}")
        
        return "\n\n".join(context_parts)
    
    def _parse_references(self, references: list[tuple[str, dict[str, object], float]]) -> list[LawReference]:
        """è§£ææ³•å¾‹å¼•ç”¨"""
        result = []
        for content, metadata, score in references:
            result.append(LawReference(
                law_name=str(metadata.get('law_name', 'æœªçŸ¥æ³•å¾‹')),
                article=str(metadata.get('article', 'æœªçŸ¥æ¡æ¬¾')),
                content=content,
                relevance=round(1 - score, 2) if score < 1 else round(score, 2)
            ))
        return result
    
    def get_or_create_session(self, session_id: str | None = None) -> str:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id and session_id in self.conversation_histories:
            self._last_seen[session_id] = time.time()
            return session_id
        
        new_session_id = session_id or uuid.uuid4().hex
        self.conversation_histories[new_session_id] = []
        self._last_seen[new_session_id] = time.time()
        self._evict_if_needed()
        return new_session_id
    
    async def chat(
        self, 
        message: str, 
        session_id: str | None = None
    ) -> tuple[str, str, list[LawReference]]:
        """
        ä¸AIåŠ©æ‰‹å¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID
            
        Returns:
            (session_id, answer, references)
        """
        session_id = self.get_or_create_session(session_id)
        
        references = self.knowledge_base.search(message, k=5)
        context = self._build_context(references)
        
        history = self.conversation_histories.get(session_id, [])
        
        messages: list[BaseMessage] = [
            SystemMessage(content=self.SYSTEM_PROMPT.format(context=context))
        ]
        
        for msg in history[-10:]:
            if msg['role'] == 'user':
                messages.append(HumanMessage(content=msg['content']))
            else:
                messages.append(AIMessage(content=msg['content']))
        
        messages.append(HumanMessage(content=message))
        
        try:
            response = await self.llm.agenerate([messages])
            answer = response.generations[0][0].text
        except Exception:
            logger.exception("AIæœåŠ¡è°ƒç”¨å¤±è´¥")
            answer = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚æ‚¨å¯ä»¥ç¨åé‡è¯•ï¼Œæˆ–ç›´æ¥è”ç³»æˆ‘ä»¬çš„åœ¨çº¿å¾‹å¸ˆè·å–å¸®åŠ©ã€‚"
        
        history.append({'role': 'user', 'content': message})
        history.append({'role': 'assistant', 'content': answer})
        self.conversation_histories[session_id] = history[-self._max_messages_per_session:]
        self._last_seen[session_id] = time.time()
        self._evict_if_needed()
        
        parsed_refs = self._parse_references(references)
        
        return session_id, answer, parsed_refs
    
    def clear_session(self, session_id: str):
        """æ¸…é™¤ä¼šè¯å†å²"""
        if session_id in self.conversation_histories:
            del self.conversation_histories[session_id]
        self._last_seen.pop(session_id, None)
    
    async def chat_stream(
        self, 
        message: str, 
        session_id: str | None = None
    ):
        """
        æµå¼å¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID
            
        Yields:
            (event_type, data) - äº‹ä»¶ç±»å‹å’Œæ•°æ®
        """
        session_id = self.get_or_create_session(session_id)
        
        references = self.knowledge_base.search(message, k=5)
        context = self._build_context(references)
        parsed_refs = self._parse_references(references)
        
        # å…ˆå‘é€session_idå’Œå¼•ç”¨
        yield ("session", {"session_id": session_id})
        yield ("references", {"references": [ref.model_dump() for ref in parsed_refs]})
        
        history = self.conversation_histories.get(session_id, [])
        
        messages: list[BaseMessage] = [
            SystemMessage(content=self.SYSTEM_PROMPT.format(context=context))
        ]
        
        for msg in history[-10:]:
            if msg['role'] == 'user':
                messages.append(HumanMessage(content=msg['content']))
            else:
                messages.append(AIMessage(content=msg['content']))
        
        messages.append(HumanMessage(content=message))
        
        full_answer = ""
        try:
            async for chunk in self.llm.astream(messages):
                if chunk.content:
                    content = str(chunk.content)
                    full_answer += content
                    yield ("content", {"text": content})
        except Exception:
            logger.exception("AIæœåŠ¡è°ƒç”¨å¤±è´¥")
            error_msg = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
            yield ("content", {"text": error_msg})
            full_answer = error_msg
        
        # æ›´æ–°å†å²
        history.append({'role': 'user', 'content': message})
        history.append({'role': 'assistant', 'content': full_answer})
        self.conversation_histories[session_id] = history[-self._max_messages_per_session:]
        self._last_seen[session_id] = time.time()
        self._evict_if_needed()
        
        yield ("done", {"session_id": session_id})


_ai_assistant = None


def get_ai_assistant() -> AILegalAssistant:
    """è·å–AIåŠ©æ‰‹å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _ai_assistant
    if _ai_assistant is None:
        _ai_assistant = AILegalAssistant()
    return _ai_assistant
