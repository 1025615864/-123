"""ç™¾å§“æ³•å¾‹åŠ©æ‰‹ - FastAPIä¸»åº”ç”¨"""
from contextlib import asynccontextmanager
import logging
import asyncio
import os
import time
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, PlainTextResponse
from fastapi.exceptions import ResponseValidationError
from fastapi.middleware.cors import CORSMiddleware

from .config import get_settings
from .database import init_db
from .services.cache_service import cache_service
from .services.prometheus_metrics import prometheus_metrics
from .database import AsyncSessionLocal
from .routers import api_router, websocket
from .middleware.logging_middleware import RequestLoggingMiddleware, ErrorLoggingMiddleware
from .middleware.rate_limit import RateLimitMiddleware
from .middleware.metrics_middleware import MetricsMiddleware
from .middleware.envelope_middleware import EnvelopeMiddleware
from .utils.periodic_task_runner import PeriodicLockedRunner
# from .routers import ai  # AI module disabled - needs langchain dependencies

settings = get_settings()

logger = logging.getLogger(__name__)

try:
    from .routers import ai
except Exception:
    ai = None
    logger.exception("AIè·¯ç”±åŠ è½½å¤±è´¥")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    _ = app
    await init_db()

    stop_event = asyncio.Event()

    runner = PeriodicLockedRunner(stop_event=stop_event, lock_client=cache_service, logger=logger)

    scheduled_enabled = True
    redis_connected = False

    async def _scheduled_news_job(session: AsyncSession) -> object:
        from .services.news_service import news_service

        return await news_service.process_scheduled_news(session)

    async def _scheduled_news_job_wrapper() -> object:
        start = time.perf_counter()
        ok = True
        try:
            async with AsyncSessionLocal() as session:
                return await _scheduled_news_job(session)
        except Exception:
            ok = False
            raise
        finally:
            prometheus_metrics.record_job(
                name="scheduled_news",
                ok=bool(ok),
                duration_seconds=max(0.0, float(time.perf_counter() - start)),
            )

    if settings.redis_url:
        redis_connected = bool(await cache_service.connect(settings.redis_url))

    if (not settings.debug) and (not redis_connected):
        scheduled_enabled = False
        logger.warning("Redisæœªè¿æ¥ä¸”DEBUGä¸ºFalseï¼šå·²ç¦ç”¨å®šæ—¶æ–°é—»ä»»åŠ¡ï¼ˆé¿å…å¤šworkeré‡å¤æ‰§è¡Œï¼‰")

    scheduled_task: asyncio.Task[None] | None = None
    if scheduled_enabled:
        scheduled_task = asyncio.create_task(
            runner.run(
                lock_key="locks:scheduled_news",
                lock_ttl_seconds=60,
                interval_seconds=30.0,
                job=_scheduled_news_job_wrapper,
            )
        )

    rss_feeds_raw = os.getenv("RSS_FEEDS", "").strip()
    rss_ingest_enabled_raw = os.getenv("RSS_INGEST_ENABLED", "").strip().lower()
    rss_ingest_enabled_flag = rss_ingest_enabled_raw in {"1", "true", "yes", "on"}
    rss_enabled = bool(rss_feeds_raw) or bool(rss_ingest_enabled_flag) or bool(settings.debug)
    if (not settings.debug) and (not redis_connected):
        rss_enabled = False

    async def _rss_ingest_job_wrapper() -> object:
        start = time.perf_counter()
        ok = True
        try:
            async with AsyncSessionLocal() as session:
                from .services.rss_ingest_service import rss_ingest_service

                return await rss_ingest_service.run_once(session)
        except Exception:
            ok = False
            raise
        finally:
            prometheus_metrics.record_job(
                name="rss_ingest",
                ok=bool(ok),
                duration_seconds=max(0.0, float(time.perf_counter() - start)),
            )

    rss_task: asyncio.Task[None] | None = None
    if rss_enabled:
        rss_interval_seconds = float(os.getenv("RSS_INGEST_INTERVAL_SECONDS", "300").strip() or "300")
        rss_task = asyncio.create_task(
            runner.run(
                lock_key="locks:rss_ingest",
                lock_ttl_seconds=60,
                interval_seconds=rss_interval_seconds,
                job=_rss_ingest_job_wrapper,
            )
        )

    news_ai_enabled_raw = os.getenv("NEWS_AI_ENABLED", "").strip().lower()
    news_ai_enabled = news_ai_enabled_raw in {"1", "true", "yes", "on"}
    if (not settings.debug) and (not redis_connected):
        news_ai_enabled = False

    async def _news_ai_job_wrapper() -> object:
        start = time.perf_counter()
        ok = True
        try:
            async with AsyncSessionLocal() as session:
                from .services.news_ai_pipeline_service import news_ai_pipeline_service

                return await news_ai_pipeline_service.run_once(session)
        except Exception:
            ok = False
            raise
        finally:
            prometheus_metrics.record_job(
                name="news_ai_pipeline",
                ok=bool(ok),
                duration_seconds=max(0.0, float(time.perf_counter() - start)),
            )

    news_ai_task: asyncio.Task[None] | None = None
    if news_ai_enabled:
        news_ai_interval_seconds = float(os.getenv("NEWS_AI_INTERVAL_SECONDS", "120").strip() or "120")
        news_ai_task = asyncio.create_task(
            runner.run(
                lock_key="locks:news_ai_pipeline",
                lock_ttl_seconds=60,
                interval_seconds=news_ai_interval_seconds,
                job=_news_ai_job_wrapper,
            )
        )

    settlement_enabled_raw = os.getenv("SETTLEMENT_JOB_ENABLED", "").strip().lower()
    settlement_enabled_flag = settlement_enabled_raw in {"1", "true", "yes", "on"}
    settlement_enabled = bool(settlement_enabled_flag) or bool(settings.debug)
    if (not settings.debug) and (not redis_connected):
        settlement_enabled = False

    async def _settlement_job_wrapper() -> object:
        start = time.perf_counter()
        ok = True
        try:
            async with AsyncSessionLocal() as session:
                from .services.settlement_service import settlement_service

                return await settlement_service.settle_due_income_records(session)
        except Exception:
            ok = False
            raise
        finally:
            prometheus_metrics.record_job(
                name="settlement",
                ok=bool(ok),
                duration_seconds=max(0.0, float(time.perf_counter() - start)),
            )

    settlement_task: asyncio.Task[None] | None = None
    if settlement_enabled:
        settlement_interval_seconds = float(
            os.getenv("SETTLEMENT_JOB_INTERVAL_SECONDS", "3600").strip() or "3600"
        )
        settlement_task = asyncio.create_task(
            runner.run(
                lock_key="locks:settlement",
                lock_ttl_seconds=60,
                interval_seconds=settlement_interval_seconds,
                job=_settlement_job_wrapper,
            )
        )

    wechatpay_refresh_enabled_raw = os.getenv("WECHATPAY_CERT_REFRESH_ENABLED", "").strip().lower()
    wechatpay_refresh_enabled = wechatpay_refresh_enabled_raw in {"1", "true", "yes", "on"}
    if (not settings.debug) and (not redis_connected):
        wechatpay_refresh_enabled = False

    async def _wechatpay_platform_certs_refresh_job_wrapper() -> object:
        start = time.perf_counter()
        ok = True
        try:
            async with AsyncSessionLocal() as session:
                if not (
                    settings.wechatpay_mch_id
                    and settings.wechatpay_mch_serial_no
                    and settings.wechatpay_private_key
                    and settings.wechatpay_api_v3_key
                ):
                    return {"skipped": True, "reason": "wechatpay config missing"}

                from .models.system import SystemConfig
                from .utils.wechatpay_v3 import fetch_platform_certificates, dump_platform_certs_json

                certs = await fetch_platform_certificates(
                    certificates_url=settings.wechatpay_certificates_url,
                    mch_id=settings.wechatpay_mch_id,
                    mch_serial_no=settings.wechatpay_mch_serial_no,
                    mch_private_key_pem=settings.wechatpay_private_key,
                    api_v3_key=settings.wechatpay_api_v3_key,
                )
                raw = dump_platform_certs_json(certs)

                res = await session.execute(
                    select(SystemConfig).where(SystemConfig.key == "WECHATPAY_PLATFORM_CERTS_JSON")
                )
                row = res.scalar_one_or_none()
                if row is None:
                    row = SystemConfig(
                        key="WECHATPAY_PLATFORM_CERTS_JSON",
                        value=raw,
                        category="payment",
                        description="WeChatPay platform certificates cache",
                    )
                    session.add(row)
                else:
                    row.value = raw
                    row.category = "payment"
                    if not (row.description or "").strip():
                        row.description = "WeChatPay platform certificates cache"
                    session.add(row)

                await session.commit()
                return {"ok": True, "count": len(certs)}
        except Exception:
            ok = False
            raise
        finally:
            prometheus_metrics.record_job(
                name="wechatpay_platform_certs_refresh",
                ok=bool(ok),
                duration_seconds=max(0.0, float(time.perf_counter() - start)),
            )

    wechatpay_task: asyncio.Task[None] | None = None
    if wechatpay_refresh_enabled:
        interval_seconds = float(os.getenv("WECHATPAY_CERT_REFRESH_INTERVAL_SECONDS", "86400").strip() or "86400")
        wechatpay_task = asyncio.create_task(
            runner.run(
                lock_key="locks:wechatpay_platform_certs",
                lock_ttl_seconds=120,
                interval_seconds=interval_seconds,
                job=_wechatpay_platform_certs_refresh_job_wrapper,
            )
        )

    logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    if ai is not None:
        logger.info("AIåŠ©æ‰‹æ¨¡å—å·²å¯ç”¨")
    else:
        logger.info("AIåŠ©æ‰‹æ¨¡å—æœªå¯ç”¨")
    
    yield

    stop_event.set()
    for t in (scheduled_task, rss_task, news_ai_task, wechatpay_task, settlement_task):
        if t is None:
            continue
        _ = t.cancel()
        try:
            await t
        except asyncio.CancelledError:
            pass
        except Exception:
            pass

    await cache_service.disconnect()

    logger.info("åº”ç”¨å…³é—­")


app = FastAPI(
    title=settings.app_name,
    description="""
# ç™¾å§“æ³•å¾‹åŠ©æ‰‹ API

æä¾›AIæ³•å¾‹å’¨è¯¢ã€è®ºå›äº¤æµã€æ–°é—»èµ„è®¯ã€å¾‹æ‰€æŸ¥è¯¢ç­‰æœåŠ¡çš„RESTful APIã€‚

## åŠŸèƒ½æ¨¡å—

- **ğŸ‘¤ ç”¨æˆ·æ¨¡å—** - æ³¨å†Œã€ç™»å½•ã€ä¸ªäººä¿¡æ¯ç®¡ç†
- **ğŸ¤– AIå’¨è¯¢** - æ™ºèƒ½æ³•å¾‹é—®ç­”ã€ä¼šè¯ç®¡ç†
- **ğŸ“° æ–°é—»èµ„è®¯** - æ³•å¾‹æ–°é—»æµè§ˆ
- **ğŸ’¬ ç¤¾åŒºè®ºå›** - å¸–å­å‘å¸ƒã€è¯„è®ºäº’åŠ¨
- **ğŸ¢ å¾‹æ‰€æœåŠ¡** - å¾‹æ‰€/å¾‹å¸ˆæŸ¥è¯¢ã€é¢„çº¦å’¨è¯¢
- **ğŸ“„ æ–‡ä¹¦ç”Ÿæˆ** - æ³•å¾‹æ–‡ä¹¦æ¨¡æ¿ç”Ÿæˆ
- **ğŸ” å…¨å±€æœç´¢** - è·¨æ¨¡å—æœç´¢
- **âš™ï¸ ç³»ç»Ÿç®¡ç†** - é…ç½®ç®¡ç†ã€æ•°æ®ç»Ÿè®¡

## è®¤è¯æ–¹å¼

ä½¿ç”¨ JWT Bearer Token è®¤è¯ï¼Œåœ¨è¯·æ±‚å¤´ä¸­æ·»åŠ ï¼š
```
Authorization: Bearer <your_token>
```

## é”™è¯¯ç è¯´æ˜

| çŠ¶æ€ç  | è¯´æ˜ |
|--------|------|
| 200 | æˆåŠŸ |
| 400 | è¯·æ±‚å‚æ•°é”™è¯¯ |
| 401 | æœªè®¤è¯ |
| 403 | æƒé™ä¸è¶³ |
| 404 | èµ„æºä¸å­˜åœ¨ |
| 422 | æ•°æ®éªŒè¯å¤±è´¥ |
| 500 | æœåŠ¡å™¨é”™è¯¯ |
""",
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_tags=[
        {"name": "ç”¨æˆ·ç®¡ç†", "description": "ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€ä¸ªäººä¿¡æ¯ç®¡ç†"},
        {"name": "AIæ³•å¾‹åŠ©æ‰‹", "description": "AIæ™ºèƒ½æ³•å¾‹å’¨è¯¢"},
        {"name": "çŸ¥è¯†åº“ç®¡ç†", "description": "æ³•å¾‹çŸ¥è¯†åº“ä¸å’¨è¯¢æ¨¡æ¿ç®¡ç†"},
        {"name": "æ–°é—»èµ„è®¯", "description": "æ³•å¾‹æ–°é—»æµè§ˆ"},
        {"name": "ç¤¾åŒºè®ºå›", "description": "å¸–å­å‘å¸ƒã€è¯„è®ºäº’åŠ¨"},
        {"name": "å¾‹æ‰€æœåŠ¡", "description": "å¾‹æ‰€/å¾‹å¸ˆæŸ¥è¯¢"},
        {"name": "æ–‡ä¹¦ç”Ÿæˆ", "description": "æ³•å¾‹æ–‡ä¹¦æ¨¡æ¿ç”Ÿæˆ"},
        {"name": "å…¨å±€æœç´¢", "description": "è·¨æ¨¡å—æœç´¢"},
        {"name": "ç³»ç»Ÿç®¡ç†", "description": "é…ç½®ç®¡ç†ã€æ•°æ®ç»Ÿè®¡"},
        {"name": "æ–‡ä»¶ä¸Šä¼ ", "description": "æ–‡ä»¶ä¸Šä¼ ç®¡ç†"},
        {"name": "é€šçŸ¥ç®¡ç†", "description": "æ¶ˆæ¯é€šçŸ¥"},
        {"name": "æ”¯ä»˜ç®¡ç†", "description": "è®¢å•ä¸æ”¯ä»˜"},
        {"name": "WebSocket", "description": "å®æ—¶æ¶ˆæ¯"},
        {"name": "ç®¡ç†åå°", "description": "ç®¡ç†å‘˜åŠŸèƒ½"},
    ],
    contact={
        "name": "ç™¾å§“æ³•å¾‹åŠ©æ‰‹å›¢é˜Ÿ",
        "email": "support@baixing-law.com",
    },
    license_info={
        "name": "MIT License",
    }
)


@app.exception_handler(ResponseValidationError)
async def response_validation_exception_handler(request: Request, exc: ResponseValidationError):
    logger.exception("Response validation error path=%s", request.url.path)
    return JSONResponse(
        status_code=500,
        content={"detail": exc.errors() if settings.debug else "æœåŠ¡å™¨é”™è¯¯"},
    )

app.add_middleware(ErrorLoggingMiddleware)
app.add_middleware(RequestLoggingMiddleware)

app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_allow_origins,
    allow_credentials=settings.cors_allow_credentials,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ·»åŠ é€Ÿç‡é™åˆ¶ä¸­é—´ä»¶
app.add_middleware(
    RateLimitMiddleware,
    requests_per_minute=120,
    requests_per_second=20,
    excluded_paths=["/docs", "/redoc", "/openapi.json", "/health", "/api/health", "/", "/api/docs"],
    trusted_proxies=settings.trusted_proxies,
)

app.add_middleware(MetricsMiddleware)
app.add_middleware(EnvelopeMiddleware)

app.include_router(api_router, prefix="/api")
app.include_router(websocket.router)


@app.get("/")
async def root():
    """æ ¹è·¯ç”±"""
    return {
        "name": settings.app_name,
        "version": "1.0.0",
        "message": "æ¬¢è¿ä½¿ç”¨ç™¾å§“æ³•å¾‹åŠ©æ‰‹API",
        "docs": "/docs"
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}


@app.get("/metrics", include_in_schema=False)
async def prometheus_metrics_endpoint(request: Request):
    token = os.getenv("METRICS_AUTH_TOKEN", "").strip()
    if token:
        auth = str(request.headers.get("Authorization") or "").strip()
        if auth != f"Bearer {token}":
            return PlainTextResponse(content="unauthorized\n", status_code=401)

    body = prometheus_metrics.render_prometheus()
    return PlainTextResponse(content=body, media_type="text/plain; version=0.0.4")


@app.get("/api/health")
async def api_health_check():
    """å¥åº·æ£€æŸ¥ï¼ˆAPIåˆ«åï¼Œå…¼å®¹å‰ç«¯proxyï¼‰"""
    return {"status": "healthy"}


@app.get("/health/detailed")
async def health_check_detailed():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    import time
    from datetime import datetime
    
    checks: dict[str, object] = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "checks": {}
    }

    checks_detail = checks.get("checks")
    if not isinstance(checks_detail, dict):
        checks_detail = {}
        checks["checks"] = checks_detail
    
    # æ•°æ®åº“æ£€æŸ¥
    try:
        from sqlalchemy import text
        from .database import engine
        start = time.time()
        async with engine.connect() as conn:
            _ = await conn.execute(text("SELECT 1"))
        db_time = (time.time() - start) * 1000
        checks_detail["database"] = {
            "status": "ok",
            "response_time_ms": round(db_time, 2)
        }
    except Exception as e:
        checks["status"] = "degraded"
        checks_detail["database"] = {
            "status": "error",
            "error": str(e)
        }
    
    # AIæœåŠ¡æ£€æŸ¥
    if settings.openai_api_key:
        checks_detail["ai_service"] = {"status": "configured"}
    else:
        checks_detail["ai_service"] = {"status": "not_configured"}
    
    # å†…å­˜ä½¿ç”¨
    try:
        import psutil
        process = psutil.Process()
        mem_info = process.memory_info()
        rss_bytes = int(getattr(mem_info, "rss", 0) or 0)
        memory_mb = float(rss_bytes) / 1024.0 / 1024.0
        checks_detail["memory"] = {
            "status": "ok",
            "usage_mb": round(memory_mb, 2)
        }
    except ImportError:
        checks_detail["memory"] = {"status": "unknown"}
    
    return checks
